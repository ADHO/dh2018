<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>Comparing human and machine performances in transcribing 18th century handwritten Venetian script</title>
    <meta name="author" content="Sofia Ares Oliveira and Frederic Kaplan"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="Comparing human and machine performances in transcribing 18th century handwritten Venetian script"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">Comparing human and machine performances in transcribing 18th century handwritten Venetian script</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="ARES_OLIVEIRA_Sofia_Comparing_human_and_machine_performances.xml">XML</a>
    </div>
    <!--TEI front-->
    <!--TEI body-->
    <div class="DH-Heading1" id="index.xml-body.1_div.1">
      <h2 class="DH-Heading1">
        <span class="headingNumber">1. </span>
        <span class="head">Introduction</span>
      </h2>
      <p>Automatic transcription of handwritten texts has made important progress in the recent years (Sanchez et al., 2014; Sanchez et al., 2015, Sanchez et al., 2016). This increase in performance, essentially due to new architectures combining convolutional neural networks with recurrent neutral networks, opens new avenues for searching in large databases of archival and library records. This paper reports on our recent progress in making million digitized Venetian documents searchable, focusing on a first subset of 18th century fiscal documents from the Venetian State Archives (Condizione di Decima, Quaderni dei Trasporti, Catastici). For this study, about 23'000 image segments containing 55'000 Venetian names of persons and places were manually transcribed by archivists, trained to read such kind of handwritten script, during an annotation phase that lasted 2 years. This annotated dataset was used to train and test a deep learning architecture, with the objective of making the entire set of more than 2 million pages searchable. As described in the following paragraphs, performance levels (about 10% character error rate) are satisfactory for search use cases, which demonstrates that such kinds of approaches are viable at least for this typology of handwritten scripts. This paper compares this level of reading performance with the reading capabilities of Italian-speaking transcribers, preselected with a test based on 100 transcriptions. More than 8500 new human transcriptions were produced, confirming that the amateur transcribers were not as good as the expert. However, on average, the machine outperforms the amateur transcribers in this transcription tasks.</p>
    </div>
    <div class="DH-Heading1" id="index.xml-body.1_div.2">
      <h2 class="DH-Heading1">
        <span class="headingNumber">2. </span>
        <span class="head">Machine performance</span>
      </h2>
      <p class="No Spacing">We developed a transcription system based on the combination of convolutional and recurrent neural networks as described in 
        <a class="link_ref" href="page7">(Shi et al., 2017) </a>for handwritten text (Fig.1a) (The code is implemented in python and is available at 
        <a class="link_ref" href="https://github.com/solivr/tf-crnn">https://github.com/solivr/tf-crnn</a>). On the one hand, convolutional neural networks (CNN) capture hierarchical spatial information, with the first layers capturing low level features and later ones capturing high level ones. On the other hand, recurrent neural networks (RNN) capture temporal data, with the ability to grab contextual information within a sequence of arbitrary length. Convolutional recurrent neural networks (CRNN) combine the best of both worlds to handle multi-dimensional data as sequences.
      </p>
      <p>From an input image, the convolutional layers extract a sequence of compact representations which corresponds to the columns of the feature map. They are processed from the left to the right of the image to form a sequence of local image descriptors (Fig.1b).</p>
      <div class="figure">
        <img src="Pictures/16e8d5027b0151cc2637a05c7fed943b.png" alt="" class="block" style=" width:9.098138888888888cm; height:10.46338888888889cm;"/>
      </div>
      <p>Fig 1 (a) Network architecture. The architecture consists of three parts: 1) convolutional layers, which extract a feature sequence from the input image; 2) recurrent layers, which predict a label distribution for each frame; 3) transcription layer, which translates the per-frame predictions into the final label sequence. 
        <a class="link_ref" href="page7">(Shi et al., 2017) </a>
      </p>
      <div class="figure">
        <img src="Pictures/d94493816650c280921e20ba02d0f094.png" alt="" class="block" style=" width:5.549194444444445cm; height:4.693708333333333cm;"/>
      </div>
      <p>
        <span class="ERROR" style="color:red; font-size: 14pt; font-weight:bold;">�</span>
        <span style="display:block" class="notemarginRight aside" id="Note1">
          <span class="docxError">unable to handle picture here, no embed or link</span>
        </span>Fig 1 (b) Feature sequence 
        <a class="link_ref" href="page7">(Shi et al., 2017) </a>
      </p>
      <p>The sequence is then input to the recurrent layers which consist of stacked bidirectional long short-term memory (LSTM) cells 
        <a class="link_ref" href="page7">(Hochreiter et al., 1997). </a>LSTM cells have the ability to capture long-range dependencies but are directional, and thus only use past contexts. Since in image-based sequences context from both directions are useful and complementary, one forward and one backward LSTM cells are combined to form bidirectional LSTMs which are then stacked to have several recurrent layers. The recurrent network outputs per-frame predictions (probabilities) that need to be converted into a label sequence.
      </p>
      <p>In the transcription layer, the connectionist temporal classification (CTC) (Graves et al., 2006) is used in order to obtain the “sequence with the highest probability conditioned on the per-frame predictions". The sequence label is found by taking the most probable label at each time step and mapping the separated labels to the correct sequence label (see (Graves et al., 2006) to have the detailed explanation on how the repeated and 'blanks' labels are dealt with).</p>
      <p>The CRNN was trained on data coming from various types of Venetian handwritten documents. The dataset is composed of image segments of mainly names and places that have been transcribed by archivists in Venice. Image segments are used in order to reflect only the performance of the transcriber system, without introducing possible errors from the segmentation process. Thus, the segmentation step is not part of the proposed experiment. The set was randomly split into training and testing set and the content of the image segments ranges from one to several words (Tab.1).</p>
      <div class="table">
        <table class="rules" style="border-collapse:collapse;border-spacing:0;">
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Set</td>
            <td style="border: 1px solid black; padding: 2px;"># images segments</td>
            <td style="border: 1px solid black; padding: 2px;"># total words</td>
            <td style="border: 1px solid black; padding: 2px;">size of vocabulary</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Training set</td>
            <td style="border: 1px solid black; padding: 2px;">20712</td>
            <td style="border: 1px solid black; padding: 2px;">48628</td>
            <td style="border: 1px solid black; padding: 2px;">8848</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Testing set</td>
            <td style="border: 1px solid black; padding: 2px;">2317</td>
            <td style="border: 1px solid black; padding: 2px;">5559</td>
            <td style="border: 1px solid black; padding: 2px;">2157</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Full set</td>
            <td style="border: 1px solid black; padding: 2px;">23029</td>
            <td style="border: 1px solid black; padding: 2px;">54187</td>
            <td style="border: 1px solid black; padding: 2px;">9429</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
        </table>
      </div>
      <p>Table 1: Datasets used</p>
      <p>We show in Fig.2a and 
        <a class="link_ref" href="page4">3a </a>how words are distributed in the dataset. We de ne the vocabulary to be the set of different words. The impact factor IF is a measure of the words' distribution in the dataset and is defined as IF (i) = 
        <sup>c(</sup>
        <sub>n</sub>
        <sup>i)</sup>
        <span style="font-style:italic">hist</span>(i; c), with c the vector of counts of each vocabulary word, n the total number of words, 
        <span style="font-style:italic">hist</span> the histogram operation and 
        <span style="font-style:italic">hist</span>(i; c) the number of vocabulary words that occur i times. The left part of these plots shows that most of the words do not appear commonly but a few are very present in the dataset as it can be seen on the right of the figures (those are mainly prepositions such as `di', `de', `in', etc). The cumulative sums (Fig.2b and Fig.3b) show that common words have limited impact, but also that the system does not suffer from overfitting to the vocabulary since most of the words used for training are 'rare' in the dataset.
      </p>
      <div class="figure">
        <img src="Pictures/ebf6bd9ea5e20c461fcf677a4a6fb6be.png" alt="" class="inline" style=" width:16.002cm; height:3.663597222222222cm;"/>
      </div>
      <p>(a)</p>
      <div class="figure">
        <img src="Pictures/0d6ed6d9fa3db3a020dd7c9ee9ac235a.png" alt="" class="inline" style=" width:16.002cm; height:3.8029444444444445cm;"/>
      </div>
      <p>(b)</p>
      <p>Figure 2: Word distribution and impact factor in full dataset. We observe that 70% of the dataset is represented by words appearing less than 250 times (out of 54187 words)</p>
      <p>To evaluate the performance of the system we use the Character Error Rate (CER) measure on the test set defined as CER = (i + s + d)=n with i, s, d, n the number of character insertions, substitutions, deletions and total characters respectively. The numerical results are shown in Tab. 
        <a class="link_ref" href="page4">2.</a> Several experiments were performed using different sets of characters (called 'Alphabet' hereafter) and resulted in one model per Alphabet. A few randomly selected examples can be seen in Appendix 
        <a class="link_ref" href="page8">A.</a>
      </p>
      <p>On this dataset, our transcription system is below 10% CER, which is sufficiently good to be able to search for entities in documents using regular expressions and fuzzy matching. Moreover, we believe this performance is better than the human average and in order to verify our hypothesis, we conducted an experiment described in the following section.</p>
      <div class="figure">
        <img src="Pictures/563bd140e54c94a859de606c43ec567c.png" alt="" class="inline" style=" width:16.002cm; height:3.6759444444444442cm;"/>
      </div>
      <p>(a)</p>
      <div class="figure">
        <img src="Pictures/cf8dc62373b079eb1218e444f8db00b3.png" alt="" class="inline" style=" width:16.002cm; height:3.8029444444444445cm;"/>
      </div>
      <p>(b)</p>
      <p>Figure 3: Word distribution and impact factor in the testing dataset</p>
      <div class="table">
        <table class="rules" style="border-collapse:collapse;border-spacing:0;">
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Alphabet</td>
            <td colspan="3" style="border: 1px solid black; padding: 2px;">Set of characters</td>
            <td style="border: 1px solid black; padding: 2px;"># image segments</td>
            <td style="border: 1px solid black; padding: 2px;">CER</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Capital-lowercase-symbols</td>
            <td colspan="3" style="border: 1px solid black; padding: 2px;">A-Za-z'.,: -=</td>
            <td style="border: 1px solid black; padding: 2px;">24035</td>
            <td style="border: 1px solid black; padding: 2px;">0.089</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Capitals-lowercase-digits-symbols</td>
            <td style="border: 1px solid black; padding: 2px;">A-Za-z0-9'.,:; -</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">=()[]/</td>
            <td style="border: 1px solid black; padding: 2px;">96198</td>
            <td style="border: 1px solid black; padding: 2px;">0.045</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">Digits</td>
            <td style="border: 1px solid black; padding: 2px;">0-9</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">72326</td>
            <td style="border: 1px solid black; padding: 2px;">0.013</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
        </table>
      </div>
      <p>Table 2: The Character Error Rate (CER) for each Alphabet</p>
    </div>
    <div class="DH-Heading1" id="index.xml-body.1_div.3">
      <h2 class="DH-Heading1">
        <span class="headingNumber">3. </span>
        <span class="head">Human performance</span>
      </h2>
      <p>In order to quantify the human average error rates on our dataset, we conducted an experiment on Crowdflower's platform, where Italian speaking persons were paid to transcribe image segments of the testing set (see examples in App. 
        <a class="link_ref" href="page8">A)</a>. The contributors had to decipher a few units before being able to start the survey and during the experiment some of their transcriptions were evaluated. There were 103 evaluation questions that allowed to separate low accuracy contributors' answers from reliable ones. Each image segment was transcribed at least three times, and in total 11'727 units were transcribed. Only the answers of contributors maintaining at least 60% accuracy throughout the experiment and who transcribed at least 50 units were taken into account for the analysis. This resulted in a total of 8'674 valid transcriptions to analyze. The number of transcriptions (judgments) per contributor and its location can be seen in Fig.6.
      </p>
      <p>We compare the performance of the system and the amateur transcribers in Tab.3 and 
        <a class="link_ref" href="page5">Fig.4,5</a> (onesample t-test, p &lt; 0:005). It is clear from the graphs that the CRNN system has a better CER and WER than the human average on this dataset, and only a few contributors have lower or comparable performance to the system but is not yet as good as the expert. It is interesting to notice that the performance of the best amateur transcriber almost doubles when capital letters and punctuation are not considered (case 3) whereas the CRNN makes little improvement. Indeed, although the system has inferred some sort of weak language model, we have seen it producing unlikely transcriptions whereas the best contributor uses its knowledge of Italian proper nouns to deduce the correct transcription when some characters are di cult to read. Thus, the system's CER and WER could be reduced by using a lexicon-based transcription, where the output of the neural network would be compared to a dictionary and the closest element would be chosen.
      </p>
      <div class="table">
        <table class="rules" style="border-collapse:collapse;border-spacing:0;">
          <tr>
            <td colspan="2" style="border: 1px solid black; padding: 2px;">Case</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td colspan="2" style="border: 1px solid black; padding: 2px;">CER</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td colspan="2" style="border: 1px solid black; padding: 2px;">WER</td>
          </tr>
          <tr>
            <td colspan="2" style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">CRNN</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">contributors</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">CRNN</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">contributors</td>
          </tr>
          <tr>
            <td colspan="2" style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">0</td>
            <td style="border: 1px solid black; padding: 2px;">: No modifications (Fig.4a)</td>
            <td style="border: 1px solid black; padding: 2px;">0.0804</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.1328</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">-</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">-</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">1</td>
            <td style="border: 1px solid black; padding: 2px;">: Capital letters replaced by lowercase (Fig.4b)</td>
            <td style="border: 1px solid black; padding: 2px;">0.0768</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.1137</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">-</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">-</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">2</td>
            <td style="border: 1px solid black; padding: 2px;">: All punctuation removed (Fig.4c, 
              <a class="link_ref" href="page6">5a)</a>
            </td>
            <td style="border: 1px solid black; padding: 2px;">0.0766</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.1241</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.2709</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.4318</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;">3</td>
            <td style="border: 1px solid black; padding: 2px;">: Combination of Case 1 and Case 2 (Fig.4d, 
              <a class="link_ref" href="page6">5b)</a>
            </td>
            <td style="border: 1px solid black; padding: 2px;">0.0718</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.1047</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.2551</td>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;">0.3507</td>
          </tr>
          <tr>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
            <td style="border: 1px solid black; padding: 2px;"/>
          </tr>
        </table>
      </div>
      <p>Table 3: Comparison of Character Error Rates (CER) and Word Error Rates (WER) considering different formatting cases of the transcriptions for our system and the mean of the contributors (ground-truth and predictions are formatted in the same way)</p>
      <div class="figure">
        <img src="Pictures/9bd8970248fce9dcb1db53f97c43ee18.png" alt="" class="block" style=" width:15.510622222222223cm; height:10.148925cm;"/>
      </div>
      <p>Figure 4: Character Error Rate per contributor for different cases (refer to Tab.3).</p>
      <div class="figure">
        <img src="Pictures/13ad4c9cda41a66c8bbfa452f82a40af.png" alt="" class="block" style=" width:7.697611111111111cm; height:4.997097222222222cm;"/>
        <img src="Pictures/92d9411470314ca9c4321cb502c0f5ff.png" alt="" class="block" style=" width:7.698572222222222cm; height:4.998061111111111cm;"/>
      </div>
      <p>(a) (b)</p>
      <p>Figure 5: Word Error Rate per contributor for different cases (refer to Tab.3).</p>
      <div class="figure">
        <img src="Pictures/c6db1fb8e19e25c28aada40b5e9896ad.png" alt="" class="block" style=" width:8.460055555555556cm; height:6cm;"/>
      </div>
      <p>Figure 6: Number of judgements made (image segments transcriptions) by each contributor and its location. The contributors' ordering is the same as Fig.4a (by increasing CER)</p>
    </div>
    <div class="DH-Heading1" id="index.xml-body.1_div.4">
      <h2 class="DH-Heading1">
        <span class="headingNumber">4. </span>
        <span class="head">Perspectives</span>
      </h2>
      <p>The developed system shows promising results to make possible the textual search on digitized handwritten documents. These results open up new prospects for massive indexing, analyze and study of historical documents. We showed that the system had lower Character and Word Error Rates than the human average, thus being sufficiently reliable to use for searching purposes. Further work will focus on improving the architecture of the model, especially the CNN. We will also explore the possibility of lexicon- or rule-based transcription to decrease error rates.</p>
      <p>More generally, it seems that the automatic transcription is currently passing a threshold in terms of performance, now giving better results than good amateur transcribers. Future research will show how far this level of performance depends on the expert initial training set or whether, after some exposition with dozens of different scripts, the automatic transcriber may be able to generalize by itself without further specific training.</p>
    </div>
    <div class="DH-Heading1" id="index.xml-body.1_div.5">
      <h2 class="DH-Heading1">
        <span class="headingNumber">5. </span>
        <span class="head">Appendix A : Transcription examples</span>
      </h2>
      <div class="figure">
        <img src="Pictures/a1fe97aef96e57e3e0af26615e39acd9.png" alt="" class="inline" style=" width:12.590466666666666cm; height:20cm;"/>
      </div>
    </div>
    <!--TEI back-->
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w288078aab3b3b1b1b3">
          <div class="biblfree">
            <span style="font-weight:bold">A. Graves, S. Fernandez, F. Gomez, and J. Schmidhuber</span> (2006) Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks, 
            <span style="font-style:italic">Proceedings of the 23rd international conference on Machine learning</span>, pp. 369-376, ACM
          </div>
        </li>
        <li id="index.xml-bibl-w288078aab3b3b1b1b5">
          <div class="biblfree">
            <span style="font-weight:bold">S. Hochreiter and J. Schmidhuber</span> (1997) Long short-term memory, 
            <span style="font-style:italic">Neural computation</span>, vol. 9, no. 8, pp. 1735-1780, 1997.
          </div>
        </li>
        <li id="index.xml-bibl-w288078aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">J. A. Sanchez, V. Romero, A. H. Toselli, and E. Vidal</span> (2104). Icfhr2014 competition on handwritten text recognition on transcriptorium datasets (htrts) 
            <span style="font-style:italic">, Frontiers in Handwriting Recognition (ICFHR)</span>, 2014 14th International Conference on, pp. 785-790, IEEE
          </div>
        </li>
        <li id="index.xml-bibl-w288078aab3b3b1b1b9">
          <div class="biblfree">
            <span style="font-weight:bold">J. A. Sanchez, A. H. Toselli, V. Romero, and E. Vidal</span> (2015). Icdar 2015 competition htrts: Hand-written text recognition on the transcriptorium dataset, 
            <span style="font-style:italic">Document Analysis and Recognition (ICDAR)</span>, 2015 13th International Conference on, pp. 1166-1170, IEEE
          </div>
        </li>
        <li id="index.xml-bibl-w288078aab3b3b1b1c11">
          <div class="biblfree">
            <span style="font-weight:bold">J. A. Sanchez, V. Romero, A. H. Toselli, and E. Vidal</span>, (2016). Icfhr2016 competition on handwritten text recognition on the read dataset, 
            <span style="font-style:italic">Frontiers in Handwriting Recognition (ICFHR)</span>, 2016 15th International Conference on, pp. 630-635, IEEE
          </div>
        </li>
        <li id="index.xml-bibl-w288078aab3b3b1b1c13">
          <div class="biblfree">
            <span style="font-weight:bold">B. Shi, X. Bai, and C. Yao</span> (2017) An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition, 
            <span style="font-style:italic">IEEE transactions on pattern analysis and machine intelligence</span>, vol. 39, no. 11, pp. 2298-2304
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Sofia Ares Oliveira (sofia.oliveiraares@epfl.ch), EPFL, Switzerland and Frederic Kaplan (frederic.kaplan@epfl.ch), EPFL, Switzerland</address>
    </div>
  </body>
</html>
