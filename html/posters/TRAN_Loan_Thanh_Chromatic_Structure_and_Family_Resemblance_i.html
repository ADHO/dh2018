<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>Chromatic Structure and Family Resemblance in Large Art Collections — Exemplary Quantification and Visualizations</title>
    <meta name="author" content="Loan T Tran , Kelly Park , Poshen Lee , Jevin West , and Maximilian Schich"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="Chromatic Structure and Family Resemblance in Large Art Collections — Exemplary Quantification and Visualizations"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">Chromatic Structure and Family Resemblance in Large Art Collections — Exemplary Quantification and Visualizations</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="TRAN_Loan_Thanh_Chromatic_Structure_and_Family_Resemblance_i.xml">XML</a>
    </div>
    <!--TEI front-->
    <!--TEI body-->
    <p>Computational pattern recognition has made ground-breaking progress in recent years by combining advanced methods of machine learning with ever increasing amounts of visual data. Algorithms that learn to learn, combined with massive parallel computation in so-called GPU clusters, and billions of images a day acquired via sensors, or uploaded by Web users, have led to a situation where computers are able to recognize faces, spot cats in any body-configuration, and even drive cars without human interaction. In Art History such advanced methods of pattern recognition increasingly aim to compete with human connoisseurship. Relevant studies, for example, successfully identify duplicate photos in image archives (Resig, 2013), quickly find artworks given a certain object ( 
      <span class="A4">Crowley and Zisserman, 2014)</span>, quantify the innovativeness of paintings ( 
      <span class="A4">Elgammal and Saleh</span>, 2015), convincingly discern and date architectural styles at a mega-city scale ( 
      <span class="A4">Lee et al., 2015)</span>, and track the evolution of color contrast in Western Art from 
      <span style="font-style:italic">chiaroscuro</span> to landscape painting (Kim et al., 2014 and Lee et al., 2017). What is missing is a rigorous reconciliation between state-of-the-art computer science techniques and established art historical standards based on trained observation and hermeneutic interpretation. Such a reconciliation is hard due to both the so-called “curse of dimensionality” in machine learning, and the cognitive limit of individual researchers confronted with potentially millions of images.
    </p>
    <p>Our project aims to work towards a reconciliation of the computational and hermeneutic perspectives via two pathways. First, through visualizing the chromatic structure of paintings up to entire collections by consistently sorting color pixels, we uncover hidden color patterns of individual paintings, artist oeuvres, periods, and museum collections. Here, we also deal with a well-known multidimensional phenomenon, i.e. color, which could be a starting point to deal with hidden dimensions in machine learning using a traditional hermeneutic approach. Second, using cutting-edge deep learning algorithms and dimension reduction techniques that reduce the high dimensions of the machine learning results to a human-digestible level, we calculate visual family resemblance, generate a variety of clustering possibilities, and produce different visualizations. Combining both pathways, while performing these analyses on three different art collections, we will be able to evaluate the machine learning results, from both an art historian's and a computer scientist's perspective, in a manner that is understandable by a broad audience.</p>
    <p>We work with three datasets: the 
      <span style="font-style:italic;font-weight:bold">Dallas Museum of Art</span>, a “universal” art collection, circa 18,000 artworks; the 
      <span style="font-style:italic;font-weight:bold">Barrett collection</span>, a comprehensive private collection of Swiss art, circa 400 paintings; and 
      <span style="font-style:italic;font-weight:bold">WikiArt</span>, an encyclopedic online collection of circa 75,000 paintings. The DMA data is particularly strong in its six-thousand-year coverage, well in line with the exponential growth of world population and cultural production. The Swiss art collection, including high resolution images taken under controlled lighting conditions, is strong in its topical coherence. The WikiArt dataset, though subjects to shortcomings in lighting conditions and temporal coverage, is widely used as a de facto benchmark among machine learning community, and is therefore used for comparative analysis with the other collections.
    </p>
    <div class="table">
      <table class="rules" style="border-collapse:collapse;border-spacing:0;">
        <tr>
          <td style="border: 1px solid black; padding: 2px;">
            <div class="figure">
              <img src="Pictures/f6f52fa343e6ae1c1d1f93b3f2bb3965.png" alt="" class="inline" style=" width:17.635361111111113cm; height:0.9354416666666666cm;"/>
            </div>
            <p>( 
              <span style="font-weight:bold">A</span>) Color palette of Claude Monet at DMA
            </p>
            <div class="figure">
              <img src="Pictures/43a56c7fedcd5d4e8fbed208e93f3b5c.png" alt="" class="inline" style=" width:17.63359722222222cm; height:0.8531166666666666cm;"/>
            </div>
            <p>( 
              <span style="font-weight:bold">B</span>) Color palette of Piet Mondrian at DMA
            </p>
            <div class="figure">
              <img src="Pictures/648688e92466ec2fe02b4e722b43831a.png" alt="" class="inline" style=" width:17.63359722222222cm; height:0.8739333333333333cm;"/>
            </div>
            <p>( 
              <span style="font-weight:bold">C</span>) Color palette of Georgia O’Keefe at DMA
            </p>
            <div class="figure">
              <img src="Pictures/933a2bd7e7e119f2e01948e4cc287fa6.png" alt="" class="inline" style=" width:17.635361111111113cm; height:0.8590805555555555cm;"/>
            </div>
            <p>( 
              <span style="font-weight:bold">D</span>) Color palette of Mark Rothko at DMA
            </p>
            <div class="figure">
              <img src="Pictures/97f2d18a60502603e8245fc395634189.png" alt="" class="inline" style=" width:17.635361111111113cm; height:0.8550611111111112cm;"/>
            </div>
            <p>( 
              <span style="font-weight:bold">E</span>) Color palette of Gerhard Richter at DMA
            </p>
          </td>
        </tr>
        <tr>
          <td style="border: 1px solid black; padding: 2px;">
            <p>
              <span style="font-weight:bold">Fig. 1. Colors in the oeuvre of individual artists.</span> Colors are consistently sorted by luminosity, indicating color frequency (number of pixels), equivalent to area coverage. The strips for ( 
              <span style="font-weight:bold">A</span>) Monet, ( 
              <span style="font-weight:bold">B</span>) Mondrian, ( 
              <span style="font-weight:bold">C</span>) O’Keefe, ( 
              <span style="font-weight:bold">D</span>) Rothko, and ( 
              <span style="font-weight:bold">E</span>) Richter reveal striking individual differences between artists. Similar sense-making comparison can be used to differentiate collection coverage as well as canonicity of artists, departments, and other sub-selections of works across museums.
            </p>
          </td>
        </tr>
      </table>
    </div>
    <!--TEI back-->
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w72941aab3b3b1b1b3">
          <div class="biblfree">
            <span class="A4">
              <span style="font-weight:bold">Crowley, Elliot J., and Andrew Zisserman</span>. (2014). In Search of Art. 
              <span style="font-style:italic">Workshop at the European Conference on Com</span>
              <span style="font-style:italic">puter Vision</span>. Springer International Publishing, pp. 54-70.
            </span>
            <a class="link_ref" href="https://www.robots.ox.ac.uk/~vgg/publications/2014/Crowley14a/crowley14a.pdf">https://www.robots.ox.ac.uk/~vgg/publications/2014/Crowley14a/crowley14a.pdf</a>
            <span class="A4"> </span>
          </div>
        </li>
        <li id="index.xml-bibl-w72941aab3b3b1b1b5">
          <div class="biblfree">
            <span class="A4">
              <span style="font-weight:bold">Elgammal, Ahmed, and Babak Saleh</span>. (2015). Quantifying Creativity in Art Networks. 
              <span style="font-style:italic">arXiv preprint arXiv:1506.00711</span>.
            </span>
            <a class="link_ref" href="http://arxiv.org/abs/1506.00711">http://arxiv.org/abs/1506.00711</a>
            <span class="A4"> </span>
          </div>
        </li>
        <li id="index.xml-bibl-w72941aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">Kim, Daniel, Seung-Woo Son, and Hawoong Jeong</span>. (2014) Large Scale Quantitative Analysis of Painting Arts. 
            <span style="font-style:italic">Scientific Reports</span> 4: 7370. 
            <a class="link_ref" href="https://www.nature.com/articles/srep07370">https://www.nature.com/articles/srep07370</a>
          </div>
        </li>
        <li id="index.xml-bibl-w72941aab3b3b1b1b9">
          <div class="biblfree">
            <span style="font-weight:bold">Lee, Byunghwee, Daniel Kim, Hawoong Jeong, Seunghye Sun, and Juyong Park</span>. (2017). Understanding the Historic Emergence of Diversity in Painting via Color Contrast. 
            <span style="font-style:italic">arXiv preprint arXiv:1701.07164</span>. 
            <a class="link_ref" href="https://arxiv.org/pdf/1701.07164.pdf">https://arxiv.org/pdf/1701.07164.pdf</a>
          </div>
        </li>
        <li id="index.xml-bibl-w72941aab3b3b1b1c11">
          <div class="biblfree">
            <span class="A4">
              <span style="font-weight:bold">Lee, Stefan, Nicolas Maisonneuve, David Crandall, Alexei A. Efros, and Josef Sivic</span>. (2015). Linking Past to Present: Discovering Style in Two Centuries of Architecture. 
              <span style="font-style:italic">IEEE </span>
              <span style="font-style:italic">International Conference on Computational Photography</span>.
            </span>
            <a class="link_ref" href="http://dx.doi.org/10.1109/ICCPHOT.2015.7168368">http://dx.doi.org/10.1109/ICCPHOT.2015.7168368</a>
            <span class="A4"> </span>
          </div>
        </li>
        <li id="index.xml-bibl-w72941aab3b3b1b1c13">
          <div class="biblfree">
            <span class="A4">
              <span style="font-weight:bold">Resig, John</span>. (2013). Using Computer Vision to Increase the Research Potential of Photo Archives. 
              <span style="font-style:italic">Journal of Digital Humanities</span> 3: 3-2.
            </span>
            <a class="link_ref" href="http://journalofdigitalhumanities.org/wp-content/uploads/2014/07/Using-Computer-Vision-to-Increase-the-Rese-John-Resig.pdf">http://journalofdigitalhumanities.org/wp-content/uploads/2014/07/Using-Computer-Vision-to-Increase-the-Rese-John-Resig.pdf</a>
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Loan T Tran (lxt110930@utdallas.edu), The University of Texas at Dallas, Richardson, TX, United States of America and Kelly Park (kelly.park@utdallas.edu), The University of Texas at Dallas, Richardson, TX, United States of America and Poshen Lee (sephonlee@gmail.com), The University of Washington, Seattle, WA, United States of America and Jevin West (jevinw@uw.edu), The University of Washington, Seattle, WA, United States of America and Maximilian Schich (Maximilian.Schich@utdallas.edu), The University of Texas at Dallas, Richardson, TX, United States of America</address>
    </div>
  </body>
</html>
